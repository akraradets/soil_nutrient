{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from glob import glob\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from components.mymodel import load_model, Models\n",
    "from components.helper import train\n",
    "from components.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_set = Imageset.k\n",
    "device = Devices.all\n",
    "environment = Environments.all\n",
    "model_name = Models.alexnet\n",
    "clip_target = True\n",
    "normalize_target = True\n",
    "epochs = 200,\n",
    "lr = 0.001\n",
    "batch_size = 200\n",
    "params:dict = dict({\n",
    "    'epochs': epochs,\n",
    "    'lr': lr,\n",
    "    'batch_size': batch_size,\n",
    "    'Imageset': image_set.value,\n",
    "    'Device': device.value,\n",
    "    'Environment': environment.value,\n",
    "    'model_name': model_name.value,\n",
    "    'clip_target': clip_target,\n",
    "    'normalize_target': normalize_target\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9463 images in ./dataset/bigset/K/*/*.\n"
     ]
    }
   ],
   "source": [
    "full_train_dataset = SoilDataset_bigset(imageset=image_set, \n",
    "                                     device=device, \n",
    "                                     environment=environment, \n",
    "                                     preprocessing=Preprocessing.training,\n",
    "                                     clip_target=clip_target,\n",
    "                                     normalize_target=normalize_target)\n",
    "train_dataset, val_dataset = random_split(dataset=full_train_dataset, lengths=[0.8,0.2], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToPILImage()\n",
       "    Resize(size=350, interpolation=bilinear, max_size=None, antialias=warn)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    RandomHorizontalFlip(p=0.5)\n",
       "    RandomVerticalFlip(p=0.5)\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"https://web-mlflow.akraradets.duckdns.org\")\n",
    "mlflow.set_experiment(experiment_name='Soil')\n",
    "mlflow.start_run()\n",
    "mlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataset:SoilDataset_bigset, epochs:int, lr:float, batch_size:int):\n",
    "    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=-1)\n",
    "    model, train_losses = train(model, loader, epochs, lr, DEVICE)\n",
    "    plt.plot(train_losses)\n",
    "    plt.title(dataset.signature)\n",
    "    plt.show()\n",
    "    return model, train_losses\n",
    "\n",
    "#We can check whether we have gpu\n",
    "DEVICE = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "# DEVICE = 'cpu'\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# img = Image.open(dataset.imgs[100])\n",
    "# # dataset.imgs[100]\n",
    "# img\n",
    "# plt.imshow( img_array )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9463 images in ./dataset/bigset/K/*/*.\n"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(350),\n",
    "    transforms.CenterCrop(224),\n",
    "    # transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "dataset = SoilDataset_bigset(imageset=image_set, device=device, environment=environment, clip_target=clip_target, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.70276832580566 0 tensor(17535314.)\n",
      "save model!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/02 21:54:15 WARNING mlflow.utils.requirements_utils: Found torch version (2.0.1+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.0.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2023/09/02 21:54:17 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.15.2+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torchvision==0.15.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_name=model_name)\n",
    "model, train_loss = train_model(model, dataset=dataset, epochs=params['epochs'], lr=params['lr'], batch_size=params['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model.to('cpu')\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(350),\n",
    "    transforms.CenterCrop(224),\n",
    "    # transforms.RandomCrop(224),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "dataset = SoilDataset_bigset(imageset=image_set, device=device, environment=environment, transform=preprocess)\n",
    "loader = DataLoader(dataset=dataset, batch_size=params['batch_size'], shuffle=False, num_workers=1)\n",
    "ys = []\n",
    "yhats = []\n",
    "pic_names = []\n",
    "with torch.no_grad():\n",
    "    for X,y,pic_name in tqdm(loader):\n",
    "        yhat = model(X)\n",
    "        pic_names.append(list(pic_name))\n",
    "        ys.append(y.reshape(-1))\n",
    "        yhats.append(yhat.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([np.hstack(ys), np.hstack(yhats), np.hstack(pic_names)]).T\n",
    "df.rename(columns = {\n",
    "    0:'Target',\n",
    "    1:'Predict',\n",
    "    2:'Image name'\n",
    "}, inplace=True)\n",
    "df.set_index('Image name', inplace=True)\n",
    "artifact_name:str = os.path.join('artifact','inference.csv')\n",
    "df.to_csv(artifact_name)\n",
    "mlflow.log_artifact(artifact_name)\n",
    "mlflow.end_run()\n",
    "os.remove(artifact_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
