{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from components.mymodel import load_model, get_model\n",
    "from components.helper import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import io\n",
    "\n",
    "class SoilDataset_phone(Dataset):\n",
    "    def __init__(self, dataset_path:str, image_set:str, transform=None):\n",
    "        assert os.path.exists(dataset_path), f\"Path is not exist.\"\n",
    "\n",
    "        image_folder = os.path.join(dataset_path, image_set)\n",
    "        assert os.path.exists(image_folder), f\"image_set={image_set} is not exists in {dataset_path}.\"\n",
    "        self.imgs = glob(os.path.join(image_folder,'*'))\n",
    "        print(f\"Found {len(self.imgs)} images in {image_folder}.\")\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "        path, img_name_w_ext = os.path.split(img_path)\n",
    "        name, ext = os.path.splitext(img_name_w_ext)\n",
    "        # print(name)\n",
    "        id, phone_brand, OM, lab_no, soil_character, place, variant = name.split('_')\n",
    "        y = float(OM)\n",
    "        y = torch.tensor(y)\n",
    "        # print(y)\n",
    "        X = io.read_image(img_path)\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X.float(), y.float(), img_name_w_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "#We can check whether we have gpu\n",
    "DEVICE = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "# DEVICE = 'cpu'\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, image_set:str, epochs:int, lr:float, save_path:str):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        # transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "\n",
    "    dataset = SoilDataset_phone(dataset_path='./dataset/phones/', image_set=image_set, transform=preprocess)\n",
    "    loader = DataLoader(dataset=dataset, batch_size=100, shuffle=True, num_workers=16)\n",
    "    model, train_losses = train(model, loader, epochs, lr, DEVICE, save_path)\n",
    "    plt.plot(train_losses)\n",
    "    plt.title(image_set)\n",
    "    plt.show()\n",
    "    return model, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2355 images in ./dataset/phones/All.\n",
      "90.59462571144104 0 tensor(287.9718)\n",
      "99.48640298843384 1 tensor(181.9653)\n",
      "99.16231203079224 2 tensor(161.5345)\n",
      "98.94897222518921 3 tensor(152.2581)\n",
      "99.16668319702148 4 tensor(146.9093)\n",
      "99.69530010223389 5 tensor(139.9800)\n",
      "96.74688911437988 6 tensor(130.2754)\n",
      "98.65414619445801 7 tensor(112.4331)\n",
      "99.21304821968079 8 tensor(93.1612)\n",
      "97.01628112792969 9 tensor(77.7088)\n",
      "98.39907264709473 10 tensor(69.6770)\n",
      "99.22574925422668 11 tensor(65.7657)\n",
      "98.34354782104492 12 tensor(64.0383)\n",
      "96.12553906440735 13 tensor(61.3674)\n",
      "98.1189432144165 14 tensor(59.2101)\n",
      "108.18712401390076 15 tensor(58.0132)\n",
      "97.08176112174988 16 tensor(55.7555)\n",
      "101.9362223148346 17 tensor(55.1697)\n",
      "98.91322755813599 18 tensor(53.9192)\n",
      "99.35451078414917 19 tensor(52.5128)\n",
      "99.33327913284302 20 tensor(58.2154)\n",
      "98.50295948982239 21 tensor(52.5908)\n",
      "98.2433910369873 22 tensor(51.5805)\n",
      "98.2453784942627 23 tensor(52.9168)\n",
      "98.09355545043945 24 tensor(50.2367)\n",
      "99.99948239326477 25 tensor(50.3010)\n",
      "99.3912284374237 26 tensor(49.4916)\n",
      "98.25807809829712 27 tensor(48.5171)\n",
      "98.44756531715393 28 tensor(49.0138)\n",
      "99.69008564949036 29 tensor(49.9068)\n",
      "98.57837533950806 30 tensor(48.9756)\n",
      "99.23135638237 31 tensor(48.3715)\n",
      "98.5292022228241 32 tensor(47.4089)\n",
      "97.46227884292603 33 tensor(47.9226)\n",
      "97.20618844032288 34 tensor(47.1000)\n",
      "98.19012570381165 35 tensor(47.5456)\n",
      "97.80627679824829 36 tensor(48.0901)\n",
      "97.10242581367493 37 tensor(47.1244)\n",
      "98.86022710800171 38 tensor(45.3132)\n",
      "97.68608713150024 39 tensor(46.7989)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Continue\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# model = get_model(model_name=model_name, image_set=image_set)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# From scratch\u001b[39;00m\n\u001b[1;32m     21\u001b[0m model \u001b[39m=\u001b[39m load_model(model_name\u001b[39m=\u001b[39mmodel_name)\n\u001b[0;32m---> 22\u001b[0m model, train_loss \u001b[39m=\u001b[39m train_model(model, image_set, epochs, lr, save_path\u001b[39m=\u001b[39;49msave_path)\n\u001b[1;32m     23\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[1;32m     24\u001b[0m \u001b[39m# torch.save(model.state_dict(), os.path.join(weight_path,f\"{image_set}.pth\"))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, image_set, epochs, lr, save_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m dataset \u001b[39m=\u001b[39m SoilDataset_phone(dataset_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./dataset/phones/\u001b[39m\u001b[39m'\u001b[39m, image_set\u001b[39m=\u001b[39mimage_set, transform\u001b[39m=\u001b[39mpreprocess)\n\u001b[1;32m     15\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mdataset, batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m model, train_losses \u001b[39m=\u001b[39m train(model, loader, epochs, lr, DEVICE, save_path)\n\u001b[1;32m     17\u001b[0m plt\u001b[39m.\u001b[39mplot(train_losses)\n\u001b[1;32m     18\u001b[0m plt\u001b[39m.\u001b[39mtitle(image_set)\n",
      "File \u001b[0;32m~/projects/components/helper.py:17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, epochs, lr, DEVICE, save_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     16\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfor\u001b[39;00m b, (image, label, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[1;32m     18\u001b[0m     \u001b[39m# print(f'start:{b}')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m#image: (B, C, W, H)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m#label: (B)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m     22\u001b[0m     label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(DEVICE)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# image_set_list = next(os.walk('./dataset/phones/'))[1]\n",
    "train_losses = []\n",
    "# mobilenet_v3_large\n",
    "# resnet50\n",
    "# efficientnet_v2_l\n",
    "# alexnet\n",
    "model_name = 'alexnet'\n",
    "weight_path = f'./weight/{model_name}'\n",
    "epochs = 300\n",
    "lr = 0.00001\n",
    "\n",
    "if(os.path.exists(weight_path) == False):\n",
    "    os.makedirs(weight_path)\n",
    "# for image_set in image_set_list:\n",
    "    # if(image_set == 'Apple'): continue\n",
    "image_set = 'All'\n",
    "save_path =  os.path.join(weight_path,f\"{image_set}.pth\")\n",
    "# Continue\n",
    "# model = get_model(model_name=model_name, image_set=image_set)\n",
    "# From scratch\n",
    "model = load_model(model_name=model_name)\n",
    "model, train_loss = train_model(model, image_set, epochs, lr, save_path=save_path)\n",
    "train_losses.append(train_loss)\n",
    "# torch.save(model.state_dict(), os.path.join(weight_path,f\"{image_set}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
