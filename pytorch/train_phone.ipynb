{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from components.mymodel import load_model, get_model\n",
    "from components.helper import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import io\n",
    "\n",
    "class SoilDataset_phone(Dataset):\n",
    "    def __init__(self, dataset_path:str, image_set:str, transform=None):\n",
    "        assert os.path.exists(dataset_path), f\"Path is not exist.\"\n",
    "\n",
    "        image_folder = os.path.join(dataset_path, image_set)\n",
    "        assert os.path.exists(image_folder), f\"image_set={image_set} is not exists in {dataset_path}.\"\n",
    "        self.imgs = glob(os.path.join(image_folder,'*'))\n",
    "        print(f\"Found {len(self.imgs)} images in {image_folder}.\")\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "        path, img_name_w_ext = os.path.split(img_path)\n",
    "        name, ext = os.path.splitext(img_name_w_ext)\n",
    "        # print(name)\n",
    "        id, phone_brand, OM, lab_no, soil_character, place, variant = name.split('_')\n",
    "        y = float(OM)\n",
    "        y = torch.tensor(y)\n",
    "        # print(y)\n",
    "        X = io.read_image(img_path)\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X.float(), y.float(), img_name_w_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "#We can check whether we have gpu\n",
    "DEVICE = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "# DEVICE = 'cpu'\n",
    "print(\"Device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, image_set:str, epochs:int, lr:float, save_path:str):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        # transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "\n",
    "    dataset = SoilDataset_phone(dataset_path='./dataset/phones/', image_set=image_set, transform=preprocess)\n",
    "    loader = DataLoader(dataset=dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "    model, train_losses = train(model, loader, epochs, lr, DEVICE, save_path)\n",
    "    plt.plot(train_losses)\n",
    "    plt.title(image_set)\n",
    "    plt.show()\n",
    "    return model, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2355 images in ./dataset/phones/All.\n"
     ]
    }
   ],
   "source": [
    "# image_set_list = next(os.walk('./dataset/phones/'))[1]\n",
    "train_losses = []\n",
    "# mobilenet_v3_large\n",
    "# resnet50\n",
    "# efficientnet_v2_l\n",
    "# alexnet\n",
    "model_name = 'efficientnet_v2_l'\n",
    "weight_path = f'./weight/{model_name}'\n",
    "epochs = 300\n",
    "lr = 0.0001\n",
    "\n",
    "if(os.path.exists(weight_path) == False):\n",
    "    os.makedirs(weight_path)\n",
    "# for image_set in image_set_list:\n",
    "    # if(image_set == 'Apple'): continue\n",
    "image_set = 'All'\n",
    "save_path =  os.path.join(weight_path,f\"{image_set}.pth\")\n",
    "# Continue\n",
    "# model = get_model(model_name=model_name, image_set=image_set)\n",
    "# From scratch\n",
    "model = load_model(model_name=model_name)\n",
    "model, train_loss = train_model(model, image_set, epochs, lr, save_path=save_path)\n",
    "train_losses.append(train_loss)\n",
    "# torch.save(model.state_dict(), os.path.join(weight_path,f\"{image_set}.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
