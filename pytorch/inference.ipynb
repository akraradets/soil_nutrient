{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision import io\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "\n",
    "from components.dataset import SoilDataset, SoilDataset_phone\n",
    "from components.mymodel import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(img:Image.Image, label:str, predict:str, picname:str):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.load_default()\n",
    "    # font.\n",
    "    import cv2\n",
    "    font_size = 30\n",
    "    font_path = os.path.join(cv2.__path__[0],'qt','fonts','DejaVuSans.ttf')\n",
    "    font = ImageFont.truetype(font_path, size=font_size)\n",
    "    draw.text((10, 10),f\"Label:{label}\",(0,0,0), font=font)\n",
    "    draw.text((10, 40 + font_size),f\"Predict:{predict}\",(0,0,0), font=font)\n",
    "    img.save(picname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_result(model_name:str, image_set:str):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        # transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    model = get_model(model_name=model_name, image_set=image_set)\n",
    "    dataset = SoilDataset('./dataset/OM_static_BG/', image_set, transform=preprocess)\n",
    "    loader = DataLoader(dataset=dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "    # toPIL = transforms.transforms.ToPILImage()\n",
    "    result_path = os.path.join('./result/',model_name,image_set)\n",
    "    if(os.path.exists(result_path) == False):\n",
    "        os.makedirs(result_path)\n",
    "\n",
    "    for X,y,pic_name in loader:\n",
    "        yhat = model(X).detach()[0][0]\n",
    "        img = Image.open(f'./dataset/OM_static_BG/{image_set}/{pic_name[0]}')\n",
    "        y = y[0]\n",
    "        pic_name = os.path.join(result_path,pic_name[0])\n",
    "        save_result(img, y.numpy(), yhat.numpy(), pic_name)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images in ./dataset/OM_static_BG/black.\n",
      "Found 20 images in ./dataset/OM_static_BG/white.\n"
     ]
    }
   ],
   "source": [
    "image_set_list = next(os.walk('./dataset/OM_static_BG/'))[1]\n",
    "# mobilenet_v3_large\n",
    "# resnet50\n",
    "# efficientnet_v2_l\n",
    "model_name = 'efficientnet_v2_l'\n",
    "for image_set in image_set_list:\n",
    "    run_result(model_name,image_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
