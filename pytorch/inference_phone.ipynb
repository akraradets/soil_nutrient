{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision import io\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "\n",
    "from components.dataset import SoilDataset, SoilDataset_phone\n",
    "from components.mymodel import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(img:Image.Image, label:str, predict:str, picname:str):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.load_default()\n",
    "    # font.\n",
    "    import cv2\n",
    "    font_size = 30\n",
    "    font_path = os.path.join(cv2.__path__[0],'qt','fonts','DejaVuSans.ttf')\n",
    "    font = ImageFont.truetype(font_path, size=font_size)\n",
    "    draw.text((10, 10),f\"Label:{label}\",(0,0,0), font=font)\n",
    "    draw.text((10, 40 + font_size),f\"Predict:{predict}\",(0,0,0), font=font)\n",
    "    img.save(picname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_result(model_name:str, image_set:str):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        # transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    model = get_model(model_name=model_name, image_set=image_set)\n",
    "    dataset = SoilDataset_phone('./dataset/phones', image_set, transform=preprocess)\n",
    "    loader = DataLoader(dataset=dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "    # toPIL = transforms.transforms.ToPILImage()\n",
    "    result_path = os.path.join('./result/',model_name,image_set)\n",
    "    if(os.path.exists(result_path) == False):\n",
    "        os.makedirs(result_path)\n",
    "\n",
    "    for X,y,pic_name in loader:\n",
    "        yhat = model(X).detach()[0][0]\n",
    "        img = Image.open(f'./dataset/phones/{image_set}/{pic_name[0]}')\n",
    "        y = y[0]\n",
    "        pic_name = os.path.join(result_path,pic_name[0])\n",
    "        save_result(img, y.numpy(), yhat.numpy(), pic_name)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 775 images in ./dataset/phones/Apple.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39malexnet\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m image_set \u001b[39min\u001b[39;00m image_set_list:\n\u001b[0;32m----> 8\u001b[0m     run_result(model_name,image_set)\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mrun_result\u001b[0;34m(model_name, image_set)\u001b[0m\n\u001b[1;32m     23\u001b[0m y \u001b[39m=\u001b[39m y[\u001b[39m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m pic_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(result_path,pic_name[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m save_result(img, y\u001b[39m.\u001b[39;49mnumpy(), yhat\u001b[39m.\u001b[39;49mnumpy(), pic_name)\n",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m, in \u001b[0;36msave_result\u001b[0;34m(img, label, predict, picname)\u001b[0m\n\u001b[1;32m      9\u001b[0m draw\u001b[39m.\u001b[39mtext((\u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m),\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLabel:\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,(\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m), font\u001b[39m=\u001b[39mfont)\n\u001b[1;32m     10\u001b[0m draw\u001b[39m.\u001b[39mtext((\u001b[39m10\u001b[39m, \u001b[39m40\u001b[39m \u001b[39m+\u001b[39m font_size),\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredict:\u001b[39m\u001b[39m{\u001b[39;00mpredict\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,(\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m), font\u001b[39m=\u001b[39mfont)\n\u001b[0;32m---> 11\u001b[0m img\u001b[39m.\u001b[39;49msave(picname)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py:2428\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2426\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mr+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2427\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2428\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mw+b\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2430\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2431\u001b[0m     save_handler(\u001b[39mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_set_list = next(os.walk('./dataset/phones/'))[1]\n",
    "# mobilenet_v3_large\n",
    "# resnet50\n",
    "# efficientnet_v2_l\n",
    "# alexnet\n",
    "model_name = 'alexnet'\n",
    "for image_set in image_set_list:\n",
    "    run_result(model_name,image_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
